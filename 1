1. DFS and BFS
#DFS
visited =[] 
def dfs(visited, graph, node):
    if node not in visited:
        print (node,end=' ')
        visited.append(node)
        for neighbour in graph[node]:
            dfs(visited, graph, neighbour)
graph = {
  5 : [3,7],
  3: [2, 4],
  7 : [8],
  2 : [],
  4 : [8],
  8 : []
}
print("Following is the Depth-First Search:")
dfs(visited, graph, 5)

#BFS
visited=[]
queue=[]
def bfs(visted,graph,node): 
    visted.append(node)
    queue.append(node)

    while queue:
        m=queue.pop(0)
        print(m,end=' ')
        for neighbour in graph[m]:
            if neighbour not in visited:
                visited.append(neighbour)
                queue.append(neighbour)
graph = {
    0: [1, 2], 
    1: [2], 
    2: [3], 
    3: [1, 2]
    } 
print("\nFollowing is Breadth First Traversal:") 
bfs(visited,graph,0)




2. A* algorithm
def aStarAlgo(start_node, stop_node): 
    open_set = set(start_node) 
    closed_set = set() 
    g = {} 
    parents = {}
    g[start_node] = 0
    parents[start_node] = start_node 
    while len(open_set) > 0: 
        n = None
        for v in open_set: 
            if n == None or g[v] + heuristic(v) < g[n] + heuristic(n): 
                n = v 
        if n == stop_node or Graph_nodes[n] == None: 
            pass
        else: 
            for (m, weight) in get_neighbors(n): 
                if m not in open_set and m not in closed_set: 
                    open_set.add(m) 
                    parents[m] = n 
                    g[m] = g[n] + weight 
                else: 
                    if g[m] > g[n] + weight: 
                        g[m] = g[n] + weight 
                        parents[m] = n 
                        if m in closed_set: 
                            closed_set.remove(m) 
                            open_set.add(m) 
        if n == None: 
            print('Path does not exist!') 
            return None
        if n == stop_node: 
            path = [] 
            while parents[n] != n: 
                path.append(n) 
                n = parents[n] 
            path.append(start_node) 
            path.reverse() 
            print('Path found: {}'.format(path)) 
            return path 
        open_set.remove(n) 
        closed_set.add(n) 
    print('Path does not exist!') 
    return None

def get_neighbors(v): 
    if v in Graph_nodes: 
        return Graph_nodes[v] 
    else: 
        return None

def heuristic(n): 
    H_dist = { 
        'A': 11, 
        'B': 6, 
        'C': 99, 
        'D': 1, 
        'E': 7, 
        'G': 0, 
    } 
    return H_dist[n] 

Graph_nodes = { 
    'A': [('B', 2), ('E', 3)], 
    'B': [('C', 1),('G', 9)], 
    'C': None, 
    'E': [('D', 6)], 
    'D': [('G', 1)], 
} 

aStarAlgo('A', 'G')




3. Candidate
import csv 
with open("trainingdata.csv") as f: 
    csv_file = csv.reader(f) 
    data = list(csv_file) 
    specific = data[1][:-1] 
    general = [['?' for i in range(len(specific))] for j in range(len(specific))] 
    for i in data: 
        if i[-1] == "Yes": 
            for j in range(len(specific)): 
                if i[j] != specific[j]: 
                    specific[j] = "?"
                    general[j][j] = "?"
        elif i[-1] == "No": 
            for j in range(len(specific)): 
                if i[j] != specific[j]: 
                    general[j][j] = specific[j] 
                else: 
                    general[j][j] = "?"
        print("\nStep " + str(data.index(i)+1) + " of Candidate Elimination Algorithm") 
        print(specific) 
        print(general) 
        gh = [] # gh = general Hypothesis
        for i in general: 
            for j in i: 
                if j != '?': 
                    gh.append(i) 
                    break
        print("\nFinal Specific hypothesis:\n", specific) 
        print("\nFinal General hypothesis:\n", gh)




4. KNN
#KNN 
from sklearn.model_selection import train_test_split 
from sklearn.neighbors import KNeighborsClassifier 
#from sklearn.neighbours import KNeighboursClassifier
from sklearn import datasets 
iris=datasets.load_iris() 
print("Iris Data Set Loaded...") 
x_train,x_test,y_train,y_test=train_test_split(iris.data,iris.target,test_size=0.1) 
for i in range(len (iris.target_names)): 
    print("label",i,"-",str(iris.target_names[i])) 
classifier=KNeighborsClassifier(n_neighbors=3) 
classifier.fit(x_train,y_train) 
y_pred=classifier.predict(x_test) 
print("results of classification using k-nn with k=3") 
for r in range(0,len(x_test)): 
    print("sample:",str(x_test[r]),"Actual-label:",str(y_test[r]),"predicted-label:",str(y_pred[r])) 
    print("classification Accuracy:",classifier.score(x_test,y_test))




5. Local Regression (LWR)
import numpy as np 
import matplotlib.pyplot as plt 
def local_regression(x0,X,Y,tau):
    x0=[1,x0] 
    X=[[1,i] for i in X] 
    X=np.asarray(X) 
    xw=(X.T)*np.exp(np.sum((X-x0)**2,axis=1)/(-2*tau**2)) 
    beta=np.linalg.pinv(xw @X) @xw @Y 
    beta=beta@x0 
    return beta

def draw(tau): 
    prediction=[local_regression(x0,X,Y,tau) for x0 in domain] 
    plt.plot(X,Y,'o',color='black') 
    plt.plot(domain,prediction,color='red') 
    plt.show() 
X=np.linspace(-3,3,num=1000) 
domain=X 
Y=np.log(np.abs(X ** 2-1)+.5) 
draw(10) 
draw(0.1) 
draw(0.01) 
draw(0.001) 




6. Naive Bayesian
import pandas as pd 
from sklearn import tree 
from sklearn.preprocessing import LabelEncoder 
from sklearn.naive_bayes import GaussianNB 
# Load Data from CSV
data = pd.read_csv('tennisdata.csv') 
print("The first 5 Values of data is :\n", data.head()) 
# obtain train data and train output
X = data.iloc[:, :-1] 
print("\nThe First 5 values of the train data is\n", X.head()) 
y = data.iloc[:, -1] 
print("\nThe First 5 values of train output is\n", y.head()) 
# convert them in numbers
le_outlook = LabelEncoder() 
X.Outlook = le_outlook.fit_transform(X.Outlook) 
le_Temperature = LabelEncoder() 
X.Temperature = le_Temperature.fit_transform(X.Temperature) 
le_Humidity = LabelEncoder() 
X.Humidity = le_Humidity.fit_transform(X.Humidity) 
le_Windy = LabelEncoder() 
X.Windy = le_Windy.fit_transform(X.Windy) 
print("\nNow the Train output is\n", X.head()) 
le_PlayTennis = LabelEncoder() 
y = le_PlayTennis.fit_transform(y) 
print("\nNow the Train output is\n",y) 
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20) 
classifier = GaussianNB() 
classifier.fit(X_train, y_train) 
from sklearn.metrics import accuracy_score 
print("Accuracy is:", accuracy_score(classifier.predict(X_test), y_test))
